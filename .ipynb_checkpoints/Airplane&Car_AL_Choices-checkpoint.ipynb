{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6MWwUTInv-oj"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "from scipy import stats\n",
    "from pylab import rcParams\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, \\\n",
    "    GradientBoostingClassifier\n",
    "from keras import backend as K\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Model\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras import applications\n",
    "import glob\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "import glob\n",
    "import platform\n",
    "import time\n",
    "from PIL import Image\n",
    "from skimage.feature import hog\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "from sklearn.svm import LinearSVC\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "import cv2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s2coy8C7xGqS"
   },
   "outputs": [],
   "source": [
    "class BaseModel(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit_predict(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "class SvmModel(BaseModel):\n",
    "\n",
    "    model_type = 'Support Vector Machine with linear Kernel'\n",
    "    def fit_predict(self, X_train, y_train, X_val, X_test, c_weight):\n",
    "        print ('training svm...')\n",
    "        self.classifier = SVC(C=1, kernel='linear', probability=True,\n",
    "                              class_weight=c_weight)\n",
    "        self.classifier.fit(X_train, y_train)\n",
    "        self.test_y_predicted = self.classifier.predict(X_test)\n",
    "        self.val_y_predicted = self.classifier.predict(X_val)\n",
    "        return (X_train, X_val, X_test, self.val_y_predicted,\n",
    "                self.test_y_predicted)\n",
    "\n",
    "\n",
    "class LogModel(BaseModel):\n",
    "\n",
    "    model_type = 'Multinominal Logistic Regression' \n",
    "    \n",
    "    def fit_predict(self, X_train, y_train, X_val, X_test, c_weight):\n",
    "        print ('training multinomial logistic regression')\n",
    "        train_samples = X_train.shape[0]\n",
    "        self.classifier = LogisticRegression(\n",
    "            C=50. / train_samples,\n",
    "            multi_class='multinomial',\n",
    "            penalty='l1',\n",
    "            solver='saga',\n",
    "            tol=0.1,\n",
    "            class_weight=c_weight,\n",
    "            )\n",
    "        self.classifier.fit(X_train, y_train)\n",
    "        self.test_y_predicted = self.classifier.predict(X_test)\n",
    "        self.val_y_predicted = self.classifier.predict(X_val)\n",
    "        return (X_train, X_val, X_test, self.val_y_predicted,\n",
    "                self.test_y_predicted)\n",
    "\n",
    "class RfModel(BaseModel):\n",
    "\n",
    "    model_type = 'Random Forest'\n",
    "    \n",
    "    def fit_predict(self, X_train, y_train, X_val, X_test, c_weight):\n",
    "        print ('training random forest...')\n",
    "        self.classifier = RandomForestClassifier(n_estimators=500, class_weight=c_weight)\n",
    "        self.classifier.fit(X_train, y_train)\n",
    "        self.test_y_predicted = self.classifier.predict(X_test)\n",
    "        self.val_y_predicted = self.classifier.predict(X_val)\n",
    "        return (X_train, X_val, X_test, self.val_y_predicted, self.test_y_predicted)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NEcquMhTzqlC"
   },
   "outputs": [],
   "source": [
    "class TrainModel:\n",
    "\n",
    "    def __init__(self, model_object):        \n",
    "        self.accuracies = []\n",
    "        self.model_object = model_object()        \n",
    "\n",
    "    def print_model_type(self):\n",
    "        print (self.model_object.model_type)\n",
    "\n",
    "    # we train normally and get probabilities for the validation set. i.e., we use the probabilities to select the most uncertain samples\n",
    "\n",
    "    def train(self, X_train, y_train, X_val, X_test, c_weight):\n",
    "        print ('Train set:', X_train.shape, 'y:', y_train.shape)\n",
    "        print ('Val   set:', X_val.shape)\n",
    "        print ('Test  set:', X_test.shape)\n",
    "        t0 = time.time()\n",
    "        (X_train, X_val, X_test, self.val_y_predicted,\n",
    "         self.test_y_predicted) = \\\n",
    "            self.model_object.fit_predict(X_train, y_train, X_val, X_test, c_weight)\n",
    "        self.run_time = time.time() - t0\n",
    "        return (X_train, X_val, X_test)  \n",
    "    # we return them in case we use PCA, with all the other algorithms, this is not needed.\n",
    "\n",
    "    # we want accuracy only for the test set\n",
    "\n",
    "    def get_test_accuracy(self, i, y_test):\n",
    "        classif_rate = np.mean(self.test_y_predicted.ravel() == y_test.ravel()) * 100\n",
    "        self.accuracies.append(classif_rate)               \n",
    "        print('--------------------------------')\n",
    "        print('Iteration:',i)\n",
    "        print('--------------------------------')\n",
    "        print('y-test set:',y_test.shape)\n",
    "        print('Example run in %.3f s' % self.run_time,'\\n')\n",
    "        print(\"Accuracy rate for %f \" % (classif_rate))    \n",
    "        print(\"Classification report for classifier %s:\\n%s\\n\" % (self.model_object.classifier, metrics.classification_report(y_test, self.test_y_predicted)))\n",
    "        print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(y_test, self.test_y_predicted))\n",
    "        print('--------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ni-E8tN7yYX2"
   },
   "outputs": [],
   "source": [
    "class BaseSelectionFunction(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def select(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "class RandomSelection(BaseSelectionFunction):\n",
    "\n",
    "    @staticmethod\n",
    "    def select(probas_val, initial_labeled_samples):\n",
    "        random_state = check_random_state(0)\n",
    "        selection = np.random.choice(probas_val.shape[0], initial_labeled_samples, replace=False)\n",
    "        print('++++++++++++++++++++++++++++++++++++++++++++++1')\n",
    "#     print('uniques chosen:',np.unique(selection).shape[0],'<= should be equal to:',initial_labeled_samples)\n",
    "\n",
    "        return selection\n",
    "\n",
    "\n",
    "\n",
    "class EntropySelection(BaseSelectionFunction):\n",
    "\n",
    "    @staticmethod\n",
    "    def select(probas_val, initial_labeled_samples):\n",
    "        e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
    "        selection = (np.argsort(e)[::-1])[:initial_labeled_samples]\n",
    "        print('++++++++++++++++++++++++++++++++++++++++++++++')\n",
    "        print(str(np.argsort(e)[::-1]))\n",
    "        return selection\n",
    "      \n",
    "      \n",
    "class MarginSamplingSelection(BaseSelectionFunction):\n",
    "\n",
    "    @staticmethod\n",
    "    def select(probas_val, initial_labeled_samples):\n",
    "        print('++++++++++++++++++++++++++++++++++++++++++++++2')\n",
    "        rev = np.sort(probas_val, axis=1)[:, ::-1]\n",
    "        values = rev[:, 0] - rev[:, 1]\n",
    "        selection = np.argsort(values)[:initial_labeled_samples]\n",
    "        return selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5aRcKj4D0SQJ"
   },
   "outputs": [],
   "source": [
    "class Normalize(object):\n",
    "    \n",
    "    def normalize(self, X_train, X_val, X_test):\n",
    "        self.scaler = MinMaxScaler()\n",
    "        X_train = self.scaler.fit_transform(X_train)\n",
    "        X_val   = self.scaler.transform(X_val)\n",
    "        X_test  = self.scaler.transform(X_test)\n",
    "        return (X_train, X_val, X_test) \n",
    "    \n",
    "    def inverse(self, X_train, X_val, X_test):\n",
    "        X_train = self.scaler.inverse_transform(X_train)\n",
    "        X_val   = self.scaler.inverse_transform(X_val)\n",
    "        X_test  = self.scaler.inverse_transform(X_test)\n",
    "        return (X_train, X_val, X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l1GJB6Kb0e54"
   },
   "outputs": [],
   "source": [
    "def get_k_random_samples(initial_labeled_samples, X_train_full,\n",
    "                         y_train_full):\n",
    "    random_state = check_random_state(0)\n",
    "    permutation = np.random.choice(trainset_size,\n",
    "                                   initial_labeled_samples,\n",
    "                                   replace=False)\n",
    "    print ()\n",
    "    print ('initial random chosen samples', permutation.shape),\n",
    "#            permutation)\n",
    "    X_train = X_train_full[permutation]\n",
    "    y_train = y_train_full[permutation]\n",
    "    X_train = X_train.reshape((X_train.shape[0], -1))\n",
    "    bin_count = np.bincount(y_train.astype('int64'))\n",
    "    unique = np.unique(y_train.astype('int64'))\n",
    "    print (\n",
    "        'initial train set:',\n",
    "        X_train.shape,\n",
    "        y_train.shape,\n",
    "        'unique(labels):',\n",
    "        bin_count,\n",
    "        unique,\n",
    "        )\n",
    "    return (permutation, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eRtOTPPvyJGx"
   },
   "outputs": [],
   "source": [
    "class TheAlgorithm(object):\n",
    "\n",
    "    accuracies = []\n",
    "\n",
    "    def __init__(self, initial_labeled_samples, model_object, selection_function):\n",
    "        self.initial_labeled_samples = initial_labeled_samples\n",
    "        self.model_object = model_object\n",
    "        self.sample_selection_function = selection_function\n",
    "\n",
    "    def run(self, X_train_full, y_train_full, X_test, y_test):\n",
    "        \n",
    "        # initialize process by applying base learner to labeled training data set to obtain Classifier\n",
    "\n",
    "        (permutation, X_train, y_train) = \\\n",
    "            get_k_random_samples(self.initial_labeled_samples,\n",
    "                                 X_train_full, y_train_full)\n",
    "        self.queried = self.initial_labeled_samples\n",
    "        self.samplecount = [self.initial_labeled_samples]\n",
    "\n",
    "        # permutation, X_train, y_train = get_equally_k_random_samples(self.initial_labeled_samples,classes)\n",
    "\n",
    "        # assign the val set the rest of the 'unlabelled' training data\n",
    "\n",
    "        X_val = np.array([])\n",
    "        y_val = np.array([])\n",
    "        X_val = np.copy(X_train_full)\n",
    "        X_val = np.delete(X_val, permutation, axis=0)\n",
    "        y_val = np.copy(y_train_full)\n",
    "        y_val = np.delete(y_val, permutation, axis=0)\n",
    "        print ('val set:', X_val.shape, y_val.shape, permutation.shape)\n",
    "        print ()\n",
    "\n",
    "        # normalize data\n",
    "\n",
    "        normalizer = Normalize()\n",
    "        X_train, X_val, X_test = normalizer.normalize(X_train, X_val, X_test)   \n",
    "        \n",
    "        self.clf_model = TrainModel(self.model_object)\n",
    "        (X_train, X_val, X_test) = self.clf_model.train(X_train, y_train, X_val, X_test, 'balanced')\n",
    "        active_iteration = 1\n",
    "        self.clf_model.get_test_accuracy(1, y_test)\n",
    "\n",
    "        # fpfn = self.clf_model.test_y_predicted.ravel() != y_val.ravel()\n",
    "        # print(fpfn)\n",
    "        # self.fpfncount = []\n",
    "        # self.fpfncount.append(fpfn.sum() / y_test.shape[0] * 100)\n",
    "\n",
    "        while self.queried < max_queried:\n",
    "\n",
    "            active_iteration += 1\n",
    "\n",
    "            # get validation probabilities\n",
    "\n",
    "            probas_val = \\\n",
    "                self.clf_model.model_object.classifier.predict_proba(X_val)\n",
    "            print ('val predicted:',\n",
    "                   self.clf_model.val_y_predicted.shape,\n",
    "                   self.clf_model.val_y_predicted)\n",
    "            print ('probabilities:', probas_val.shape, '\\n',\n",
    "                   np.argmax(probas_val, axis=1))\n",
    "\n",
    "            # select samples using a selection function\n",
    "\n",
    "            uncertain_samples = \\\n",
    "                self.sample_selection_function.select(probas_val, self.initial_labeled_samples)\n",
    "\n",
    "            # normalization needs to be inversed and recalculated based on the new train and test set.\n",
    " \n",
    "            X_train, X_val, X_test = normalizer.inverse(X_train, X_val, X_test)   \n",
    "\n",
    "            # get the uncertain samples from the validation set\n",
    "\n",
    "            print ('trainset before', X_train.shape, y_train.shape)\n",
    "            X_train = np.concatenate((X_train, X_val[uncertain_samples]))\n",
    "            y_train = np.concatenate((y_train, y_val[uncertain_samples]))\n",
    "            print ('trainset after', X_train.shape, y_train.shape)\n",
    "            self.samplecount.append(X_train.shape[0])\n",
    "\n",
    "            bin_count = np.bincount(y_train.astype('int64'))\n",
    "            unique = np.unique(y_train.astype('int64'))\n",
    "            print (\n",
    "                'updated train set:',\n",
    "                X_train.shape,\n",
    "                y_train.shape,\n",
    "                'unique(labels):',\n",
    "                bin_count,\n",
    "                unique,\n",
    "                )\n",
    "\n",
    "            X_val = np.delete(X_val, uncertain_samples, axis=0)\n",
    "            y_val = np.delete(y_val, uncertain_samples, axis=0)\n",
    "            print ('val set:', X_val.shape, y_val.shape)\n",
    "            print ()\n",
    "\n",
    "            # normalize again after creating the 'new' train/test sets\n",
    "            normalizer = Normalize()\n",
    "            X_train, X_val, X_test = normalizer.normalize(X_train, X_val, X_test)               \n",
    "\n",
    "            self.queried += self.initial_labeled_samples\n",
    "            (X_train, X_val, X_test) = self.clf_model.train(X_train, y_train, X_val, X_test, 'balanced')\n",
    "            self.clf_model.get_test_accuracy(active_iteration, y_test)\n",
    "\n",
    "        print ('final active learning accuracies',\n",
    "               self.clf_model.accuracies)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def areas(lengths,choice_str,model):\n",
    "    sum = 0.\n",
    "    i = 0\n",
    "    k=10\n",
    "    #print(lengths,ks)\n",
    "    for length in lengths:\n",
    "        lengthhere = lengths[i]\n",
    "        if i == 0:\n",
    "            sum = sum + lengthhere*k/2\n",
    "        else:\n",
    "            sum = sum + (lengthhere+lengthhere)*k/2\n",
    "        i += 1\n",
    "    #print(\"The whole area is : 50,000\")\n",
    "    print(\"Airplane & car \"+choice_str+\" \"+model+\": The area below this line is: %.2f\"%sum)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getdataset(choice):\n",
    "    if os.path.exists('bottleneck_features_test.npy') and choice == \"Pretrained\":\n",
    "        choice ='Pretrained_repeat'\n",
    "    print(\"Geting data now\")\n",
    "    print(\"The data you chose is \"+choice)\n",
    "    classifications=['airplane','car']\n",
    "    train_data_dir = 'rawdata/train/'\n",
    "    validation_data_dir = 'rawdata/test/'\n",
    "    \n",
    "    nb_train_samples = trainset_size\n",
    "    nb_validation_samples = testset_size\n",
    "\n",
    "    df_train = []\n",
    "    y_train_full=[]\n",
    "    images = os.listdir(train_data_dir)\n",
    "    for classification in classifications:\n",
    "        imagePaths = [f for f in glob.glob(train_data_dir+classification+'/'+'*.jpg')]\n",
    "        #here will take one min\n",
    "        for img in imagePaths:\n",
    "            img_data = load_img(img ,target_size=(150, 150))\n",
    "            img_data_array = img_to_array(img_data)\n",
    "            #print(img_data_array.shape)#img_data_array is (150,150,3)\n",
    "            if choice == 'Raw':\n",
    "                #will get (150*150*3)\n",
    "                img_data_flat = img_data_array.reshape(img_data_array.shape[0]*img_data_array.shape[1]*img_data_array.shape[2])\n",
    "                #print(img_data_flat.shape)\n",
    "            if choice == 'HOG' :\n",
    "                #will get (150,150)\n",
    "                img_data_flat=(img_data_array[:, :, 0] * 0.2989 + img_data_array[:, :, 1] * 0.5870 + img_data_array[:, :, 2] * 0.1140)/255.0\n",
    "                #print(img_data_flat.shape)\n",
    "            if choice == 'Pretrained' or choice == 'Pretrained_repeat':\n",
    "                #will get is (150,150,3)\n",
    "                img_data_flat= img_data_array\n",
    "                #print(img_data_flat.shape)\n",
    "            df_train.append(img_data_flat)\n",
    "            #print(classification)\n",
    "            if classification == \"airplane\":\n",
    "                y_train_full.append(0)\n",
    "            if classification == \"car\":\n",
    "                y_train_full.append(1)\n",
    "    #print(y_train_full)\n",
    "            \n",
    "\n",
    "    df_val = []\n",
    "    y_test = []\n",
    "    images = os.listdir(validation_data_dir)\n",
    "    for classification in classifications:\n",
    "        imagePaths = [f for f in glob.glob(validation_data_dir+classification+'/'+'*.jpg')]\n",
    "        for img in imagePaths:\n",
    "            img_data = load_img(img ,target_size=(150, 150))\n",
    "            img_data_array = img_to_array(img_data)\n",
    "            if choice == 'Raw':\n",
    "                #will get (150*150*3)\n",
    "                img_data_flat = img_data_array.reshape(img_data_array.shape[0]*img_data_array.shape[1]*img_data_array.shape[2])\n",
    "                #print(img_data_flat.shape)\n",
    "            if choice == 'HOG' :\n",
    "                #will get (150,150)\n",
    "                img_data_flat=(img_data_array[:, :, 0] * 0.2989 + img_data_array[:, :, 1] * 0.5870 + img_data_array[:, :, 2] * 0.1140)/255.0\n",
    "                #print(img_data_flat.shape)\n",
    "            if choice == 'Pretrained' or choice == 'Pretrained_repeat':\n",
    "                #will get is (150,150,3)\n",
    "                img_data_flat= img_data_array\n",
    "                #print(img_data_flat.shape)\n",
    "            df_val.append(img_data_flat)\n",
    "            if classification == \"airplane\":\n",
    "                    y_test.append(0)\n",
    "            if classification == \"car\":\n",
    "                    y_test.append(1)\n",
    "            #print(y_train_full)\n",
    "\n",
    "    #This will run for 10second\n",
    "    X_train_full = np.concatenate([arr[np.newaxis] for arr in df_train]).astype('float32')\n",
    "    X_test = np.concatenate([arr[np.newaxis] for arr in df_val]).astype('float32')\n",
    "\n",
    "    #将list 转成np，否则会有报错\n",
    "    y_train_full=np.array(y_train_full)\n",
    "    y_test=np.array(y_test)\n",
    "\n",
    "    if choice =='HOG':\n",
    "        X_test_new=[]\n",
    "        X_train_new=[]\n",
    "        for num in range(0,trainset_size):\n",
    "            fd = hog(X_train_full[num], orientations=12,block_norm='L1', pixels_per_cell=[8, 8], cells_per_block=[4, 4], visualize=False,transform_sqrt=False\n",
    "                    )\n",
    "            X_train_new.append(fd)\n",
    "\n",
    "        for num in range(0,testset_size):\n",
    "            fd = hog(X_test[num], orientations=12,block_norm='L1', pixels_per_cell=[8, 8], cells_per_block=[4, 4], visualize=False,\n",
    "                             transform_sqrt=True)\n",
    "            X_test_new.append(fd)\n",
    "\n",
    "        X_train_full=np.array(X_train_new)\n",
    "        X_test=np.array(X_test_new)\n",
    "\n",
    "    if choice == 'Pretrained':\n",
    "        model = applications.VGG16(include_top=False, weights='imagenet')\n",
    "        last_layer = Model(inputs=model.input, outputs=model.get_layer('block5_pool').output)\n",
    "\n",
    "        start = time.clock()\n",
    "        print(\"Process data though the pretrained mdoel(train set), it will last for about 8 mins\")\n",
    "        features = last_layer.predict(X_train_full)\n",
    "        elapsed = (time.clock() - start)\n",
    "        print(\"(should about 8 mins)Time used:\",elapsed)\n",
    "\n",
    "        start = time.clock()\n",
    "        print(\"Process data though the pretrained mdoel(test set), it will last for about 2 mins\")\n",
    "        features_test = last_layer.predict(X_test)\n",
    "        elapsed = (time.clock() - start)\n",
    "        print(\"(should about 100second)Time used:\",elapsed)\n",
    "\n",
    "        X_train_full = features.reshape(trainset_size,-1)\n",
    "        X_test=features_test.reshape(testset_size,-1)\n",
    "\n",
    "        np.save('bottleneck_features_train.npy',X_train_full)\n",
    "        np.save('bottleneck_features_test.npy',X_test)\n",
    "\n",
    "    if choice == 'Pretrained' or choice == 'Pretrained_repeat':\n",
    "        X_train_full=np.load('bottleneck_features_train.npy')\n",
    "        X_test=np.load('bottleneck_features_test.npy')\n",
    "    #print(y_train_full)\n",
    "        \n",
    "        \n",
    "    print(\"Got all data now, here is the shape of the data\")\n",
    "    print(\"X_train_full shape: \"+str(X_train_full.shape))\n",
    "    print(\"y_train_full shape: \"+str(y_train_full.shape))\n",
    "    print(\"X_test shape: \"+str(X_test.shape))\n",
    "    print(\"y_test shape: \"+str(y_test.shape))\n",
    "        \n",
    "    return (X_train_full,y_train_full,X_test,y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'500''1294'\n",
    "max_queried = 20\n",
    "Ks = [10]\n",
    "\n",
    "#True means will save, False means will not save \n",
    "save_file=True\n",
    "\n",
    "#'Raw''HOG''Pretrained'\n",
    "choices=['Pretrained','HOG']\n",
    "\n",
    "#'RfModel''LogModel''SvmModel'\n",
    "models = [SvmModel,RfModel] \n",
    "\n",
    "#'RandomSelection''MarginSamplingSelection''EntropySelection'\n",
    "selection_functions = [ MarginSamplingSelection] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset_size = 1295\n",
    "testset_size = 400\n",
    "\n",
    "choices_str=choices\n",
    "\n",
    "Ks_str = ['10'] \n",
    "\n",
    "models_str=[]\n",
    "for model in models:\n",
    "    models_str.append( model.__name__) \n",
    "\n",
    "selection_functions_str=[]\n",
    "for selection_function in selection_functions:\n",
    "    selection_functions_str.append( selection_function.__name__) \n",
    "\n",
    "stopped_at = -1 \n",
    "#the data should be put in two dir rowdata/train/ and rowdata/test/\n",
    "#data should be named as A.num.jpg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stopping at: 20\n",
      "Pretrained_repeat\n",
      "Geting data now\n",
      "The data you chose is Pretrained_repeat\n",
      "Got all data now, here is the shape of the data\n",
      "X_train_full shape: (1295, 8192)\n",
      "y_train_full shape: (1295,)\n",
      "X_test shape: (400, 8192)\n",
      "y_test shape: (400,)\n",
      "Count = 1, using model = SvmModel, selection_function = MarginSamplingSelection, k = 10, iteration = 0.\n",
      "\n",
      "initial random chosen samples (10,)\n",
      "initial train set: (10, 8192) (10,) unique(labels): [2 8] [0 1]\n",
      "val set: (1285, 8192) (1285,) (10,)\n",
      "\n",
      "Train set: (10, 8192) y: (10,)\n",
      "Val   set: (1285, 8192)\n",
      "Test  set: (400, 8192)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 1\n",
      "--------------------------------\n",
      "y-test set: (400,)\n",
      "Example run in 0.243 s \n",
      "\n",
      "Accuracy rate for 90.000000 \n",
      "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='linear', max_iter=-1, probability=True, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90       200\n",
      "           1       0.91      0.89      0.90       200\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       400\n",
      "   macro avg       0.90      0.90      0.90       400\n",
      "weighted avg       0.90      0.90      0.90       400\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[182  18]\n",
      " [ 22 178]]\n",
      "--------------------------------\n",
      "val predicted: (1285,) [0 1 0 ... 1 1 1]\n",
      "probabilities: (1285, 2) \n",
      " [1 1 1 ... 1 0 1]\n",
      "++++++++++++++++++++++++++++++++++++++++++++++2\n",
      "trainset before (10, 8192) (10,)\n",
      "trainset after (20, 8192) (20,)\n",
      "updated train set: (20, 8192) (20,) unique(labels): [ 2 18] [0 1]\n",
      "val set: (1275, 8192) (1275,)\n",
      "\n",
      "Train set: (20, 8192) y: (20,)\n",
      "Val   set: (1275, 8192)\n",
      "Test  set: (400, 8192)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 2\n",
      "--------------------------------\n",
      "y-test set: (400,)\n",
      "Example run in 0.361 s \n",
      "\n",
      "Accuracy rate for 85.250000 \n",
      "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='linear', max_iter=-1, probability=True, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.78      0.84       200\n",
      "           1       0.81      0.93      0.86       200\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       400\n",
      "   macro avg       0.86      0.85      0.85       400\n",
      "weighted avg       0.86      0.85      0.85       400\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[155  45]\n",
      " [ 14 186]]\n",
      "--------------------------------\n",
      "final active learning accuracies [90.0, 85.25]\n",
      "\n",
      "---------------------------- FINISHED ---------------------------\n",
      "\n",
      "Count = 2, using model = RfModel, selection_function = MarginSamplingSelection, k = 10, iteration = 0.\n",
      "\n",
      "initial random chosen samples (10,)\n",
      "initial train set: (10, 8192) (10,) unique(labels): [4 6] [0 1]\n",
      "val set: (1285, 8192) (1285,) (10,)\n",
      "\n",
      "Train set: (10, 8192) y: (10,)\n",
      "Val   set: (1285, 8192)\n",
      "Test  set: (400, 8192)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 1\n",
      "--------------------------------\n",
      "y-test set: (400,)\n",
      "Example run in 0.406 s \n",
      "\n",
      "Accuracy rate for 88.750000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=None, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=None, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.78      0.87       200\n",
      "           1       0.82      1.00      0.90       200\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       400\n",
      "   macro avg       0.91      0.89      0.89       400\n",
      "weighted avg       0.91      0.89      0.89       400\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[155  45]\n",
      " [  0 200]]\n",
      "--------------------------------\n",
      "val predicted: (1285,) [0 0 0 ... 1 1 1]\n",
      "probabilities: (1285, 2) \n",
      " [0 0 0 ... 1 1 1]\n",
      "++++++++++++++++++++++++++++++++++++++++++++++2\n",
      "trainset before (10, 8192) (10,)\n",
      "trainset after (20, 8192) (20,)\n",
      "updated train set: (20, 8192) (20,) unique(labels): [14  6] [0 1]\n",
      "val set: (1275, 8192) (1275,)\n",
      "\n",
      "Train set: (20, 8192) y: (20,)\n",
      "Val   set: (1275, 8192)\n",
      "Test  set: (400, 8192)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 2\n",
      "--------------------------------\n",
      "y-test set: (400,)\n",
      "Example run in 0.464 s \n",
      "\n",
      "Accuracy rate for 75.000000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=None, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=None, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80       200\n",
      "           1       1.00      0.50      0.67       200\n",
      "\n",
      "   micro avg       0.75      0.75      0.75       400\n",
      "   macro avg       0.83      0.75      0.73       400\n",
      "weighted avg       0.83      0.75      0.73       400\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[200   0]\n",
      " [100 100]]\n",
      "--------------------------------\n",
      "final active learning accuracies [88.75, 75.0]\n",
      "\n",
      "---------------------------- FINISHED ---------------------------\n",
      "\n",
      "HOG\n",
      "Geting data now\n",
      "The data you chose is HOG\n",
      "Got all data now, here is the shape of the data\n",
      "X_train_full shape: (1295, 43200)\n",
      "y_train_full shape: (1295,)\n",
      "X_test shape: (400, 43200)\n",
      "y_test shape: (400,)\n",
      "Count = 3, using model = SvmModel, selection_function = MarginSamplingSelection, k = 10, iteration = 0.\n",
      "\n",
      "initial random chosen samples (10,)\n",
      "initial train set: (10, 43200) (10,) unique(labels): [2 8] [0 1]\n",
      "val set: (1285, 43200) (1285,) (10,)\n",
      "\n",
      "Train set: (10, 43200) y: (10,)\n",
      "Val   set: (1285, 43200)\n",
      "Test  set: (400, 43200)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 1\n",
      "--------------------------------\n",
      "y-test set: (400,)\n",
      "Example run in 1.183 s \n",
      "\n",
      "Accuracy rate for 83.500000 \n",
      "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='linear', max_iter=-1, probability=True, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.73      0.82       200\n",
      "           1       0.78      0.94      0.85       200\n",
      "\n",
      "   micro avg       0.83      0.83      0.83       400\n",
      "   macro avg       0.85      0.83      0.83       400\n",
      "weighted avg       0.85      0.83      0.83       400\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[146  54]\n",
      " [ 12 188]]\n",
      "--------------------------------\n",
      "val predicted: (1285,) [0 0 1 ... 1 1 1]\n",
      "probabilities: (1285, 2) \n",
      " [0 0 0 ... 0 1 0]\n",
      "++++++++++++++++++++++++++++++++++++++++++++++2\n",
      "trainset before (10, 43200) (10,)\n",
      "trainset after (20, 43200) (20,)\n",
      "updated train set: (20, 43200) (20,) unique(labels): [ 2 18] [0 1]\n",
      "val set: (1275, 43200) (1275,)\n",
      "\n",
      "Train set: (20, 43200) y: (20,)\n",
      "Val   set: (1275, 43200)\n",
      "Test  set: (400, 43200)\n",
      "training svm...\n",
      "--------------------------------\n",
      "Iteration: 2\n",
      "--------------------------------\n",
      "y-test set: (400,)\n",
      "Example run in 1.908 s \n",
      "\n",
      "Accuracy rate for 61.500000 \n",
      "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='linear', max_iter=-1, probability=True, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.23      0.37       200\n",
      "           1       0.56      1.00      0.72       200\n",
      "\n",
      "   micro avg       0.61      0.61      0.61       400\n",
      "   macro avg       0.78      0.61      0.55       400\n",
      "weighted avg       0.78      0.61      0.55       400\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 46 154]\n",
      " [  0 200]]\n",
      "--------------------------------\n",
      "final active learning accuracies [83.5, 61.5]\n",
      "\n",
      "---------------------------- FINISHED ---------------------------\n",
      "\n",
      "Count = 4, using model = RfModel, selection_function = MarginSamplingSelection, k = 10, iteration = 0.\n",
      "\n",
      "initial random chosen samples (10,)\n",
      "initial train set: (10, 43200) (10,) unique(labels): [2 8] [0 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val set: (1285, 43200) (1285,) (10,)\n",
      "\n",
      "Train set: (10, 43200) y: (10,)\n",
      "Val   set: (1285, 43200)\n",
      "Test  set: (400, 43200)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 1\n",
      "--------------------------------\n",
      "y-test set: (400,)\n",
      "Example run in 0.740 s \n",
      "\n",
      "Accuracy rate for 50.000000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=None, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=None, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       200\n",
      "           1       0.50      1.00      0.67       200\n",
      "\n",
      "   micro avg       0.50      0.50      0.50       400\n",
      "   macro avg       0.25      0.50      0.33       400\n",
      "weighted avg       0.25      0.50      0.33       400\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[  0 200]\n",
      " [  0 200]]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/tensor/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val predicted: (1285,) [1 1 1 ... 1 1 1]\n",
      "probabilities: (1285, 2) \n",
      " [1 1 1 ... 1 1 1]\n",
      "++++++++++++++++++++++++++++++++++++++++++++++2\n",
      "trainset before (10, 43200) (10,)\n",
      "trainset after (20, 43200) (20,)\n",
      "updated train set: (20, 43200) (20,) unique(labels): [12  8] [0 1]\n",
      "val set: (1275, 43200) (1275,)\n",
      "\n",
      "Train set: (20, 43200) y: (20,)\n",
      "Val   set: (1275, 43200)\n",
      "Test  set: (400, 43200)\n",
      "training random forest...\n",
      "--------------------------------\n",
      "Iteration: 2\n",
      "--------------------------------\n",
      "y-test set: (400,)\n",
      "Example run in 0.768 s \n",
      "\n",
      "Accuracy rate for 58.750000 \n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=None, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=None, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.18      0.30       200\n",
      "           1       0.55      0.99      0.71       200\n",
      "\n",
      "   micro avg       0.59      0.59      0.59       400\n",
      "   macro avg       0.76      0.59      0.51       400\n",
      "weighted avg       0.76      0.59      0.51       400\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 36 164]\n",
      " [  1 199]]\n",
      "--------------------------------\n",
      "final active learning accuracies [50.0, 58.75]\n",
      "\n",
      "---------------------------- FINISHED ---------------------------\n",
      "\n",
      "{'Pretrained': {'SvmModel': {'MarginSamplingSelection': {'10': [[90.0, 85.25]]}}, 'RfModel': {'MarginSamplingSelection': {'10': [[88.75, 75.0]]}}}, 'HOG': {'SvmModel': {'MarginSamplingSelection': {'10': [[83.5, 61.5]]}}, 'RfModel': {'MarginSamplingSelection': {'10': [[50.0, 58.75]]}}}}\n",
      "1\n",
      "{'HOG': {'RfModel': {'MarginSamplingSelection': {'10': [[50.0, 58.75]]}}, 'SvmModel': {'MarginSamplingSelection': {'10': [[83.5, 61.5]]}}}, 'Pretrained': {'RfModel': {'MarginSamplingSelection': {'10': [[88.75, 75.0]]}}, 'SvmModel': {'MarginSamplingSelection': {'10': [[90.0, 85.25]]}}}}\n",
      "Time used: 29.71844299999998\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    " \n",
    "start = time.clock()\n",
    " \n",
    "#get the dataset here\n",
    "\n",
    "\n",
    "  \n",
    "def experiment(d, models, selection_functions, Ks, repeats, contfrom):\n",
    "    algos_temp = []\n",
    "    print ('stopping at:', max_queried)\n",
    "    count = 0\n",
    "    for choice in choices:\n",
    "        if choice not in d:\n",
    "            d[choice] = {}\n",
    "            (X_train_full,y_train_full,X_test,y_test)=getdataset(choice)\n",
    "        for model_object in models:\n",
    "            if model_object.__name__ not in d[choice]:\n",
    "                d[choice][model_object.__name__] = {}\n",
    "            for selection_function in selection_functions:\n",
    "                if selection_function.__name__ not in d[choice][model_object.__name__]:\n",
    "                    d[choice][model_object.__name__][selection_function.__name__] = {}\n",
    "\n",
    "                for k in Ks:\n",
    "                    d[choice][model_object.__name__][selection_function.__name__][str(k)] = []           \n",
    "\n",
    "                    for i in range(0, repeats):\n",
    "                        count+=1\n",
    "                        if count >= contfrom:\n",
    "                            print ('Count = %s, using model = %s, selection_function = %s, k = %s, iteration = %s.' % (count, model_object.__name__, selection_function.__name__, k, i))\n",
    "                            alg = TheAlgorithm(k, \n",
    "                                               model_object, \n",
    "                                               selection_function\n",
    "                                               )\n",
    "                            alg.run(X_train_full, y_train_full, X_test, y_test)\n",
    "                            d[choice][model_object.__name__][selection_function.__name__][str(k)].append(alg.clf_model.accuracies)\n",
    "                            if count % 5 == 0:\n",
    "                                print(json.dumps(d, indent=2, sort_keys=True))\n",
    "                            print ()\n",
    "                            print ('---------------------------- FINISHED ---------------------------')\n",
    "                            print ()\n",
    "    return d\n",
    "\n",
    "\n",
    "\n",
    "d = {}\n",
    "# print('directory dump including pickle files:', os.getcwd(), np.sort(os.listdir()))  \n",
    "# d = pickle_load('Active-learning-experiment-' + str(stopped_at) + '.pkl')  \n",
    "# print(json.dumps(d, indent=2, sort_keys=True))\n",
    "\n",
    "d = experiment(d, models, selection_functions, Ks, 1, stopped_at+1)\n",
    "print (d)\n",
    "results = json.loads(json.dumps(d, indent=2, sort_keys=True))\n",
    "print('1')\n",
    "print(results)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "elapsed = (time.clock() - start)\n",
    "print(\"Time used:\",elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Airplane & car Pretrained SvmModel: The area below this line is: 1302.50\n",
      "Airplane & car Pretrained RfModel: The area below this line is: 1193.75\n",
      "Airplane & car HOG SvmModel: The area below this line is: 1032.50\n",
      "Airplane & car HOG RfModel: The area below this line is: 837.50\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def performance_plot(fully_supervised_accuracy, dic, models, selection_functions, Ks, repeats, lowest_y):  \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot([0,500],[fully_supervised_accuracy, fully_supervised_accuracy],label = 'algorithm-upper-bound')\n",
    "    for choice_str in choices_str:\n",
    "        for model_object in models:\n",
    "          for selection_function in selection_functions:\n",
    "            for idx, k in enumerate(Ks):\n",
    "                x = np.arange(float(Ks[idx]), max_queried + float(Ks[idx]), float(Ks[idx]))            \n",
    "                filename =choice_str+'-'+ model_object + '-' +selection_function + '-' + \"10\"+'.npy'\n",
    "                mean = np.array(dic[choice_str][model_object][selection_function][k][0])\n",
    "                if(save_file==True):\n",
    "                    np.save(filename,mean)\n",
    "                ax.plot(x, mean ,label = model_object + '-' + selection_function + '-' + str(k)+'-'+choice_str)\n",
    "                areas(mean,choice_str,model_object)\n",
    "    ax.legend()\n",
    "    ax.set_xlim([0,500])\n",
    "    ax.set_ylim([0,101])\n",
    "    ax.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "performance_plot(100, \n",
    "                 d,\n",
    "                 models_str,\n",
    "                 selection_functions_str , \n",
    "                 Ks_str, \n",
    "                 1,\n",
    "                 90)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Active Learning Tutorial",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
